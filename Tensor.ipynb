{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 Tensor\n",
    "## 1.1 Introduction\n",
    "In algebra, tensor is the generalization of vector and matrix. For example, scalar can be seen as the zero order tensor, vector can be seen as the first order tensor and matrix is the second order.\n",
    "\n",
    "In PyTorch, ```torch.Tensor``` is the main tool of storing and changing data, which is similar with Numpy. However, ```Tensor``` provide more functions like computation of GPU and automatic gradient calculation. Hence, it makes ```Tensor``` suitable for deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Creation\n",
    "In this section, we would introduce some common methods of creating tensor.\n",
    "1. Initialize random matrix, using ```torch.rand()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1394, 0.8346, 0.3913],\n",
      "        [0.9298, 0.5708, 0.0141],\n",
      "        [0.7222, 0.5374, 0.3818],\n",
      "        [0.3647, 0.7618, 0.4842]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(4,3)  # Create 4*3 tensor\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Creating all zero matrix, using ```torch.zeros()```, and set the data type as long. Besides, ```torch.zero_()``` and ```torch.zeros_like()``` can be used to transfer a matrix into all zero matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.zeros(4,3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Directly using data to construct a tensor, using ```torch.tensor()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Based on existing tensor, creating a new tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[-1.4695,  0.6198,  1.4924],\n",
      "        [ 0.7782,  1.5784,  0.6864],\n",
      "        [-1.7062,  0.6917, -1.5334],\n",
      "        [-0.5476,  0.0465,  0.2455]])\n",
      "torch.Size([4, 3])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(4, 3, dtype=torch.double)\n",
    "print(x)\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)\n",
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Common construction methods of Tensor\n",
    "\n",
    "Function | Application\n",
    "-------- | -----------\n",
    "Tensor(sizes) | basic construction function\n",
    "tensor(data) | similar with np.array\n",
    "ones(sizes)  | all 1\n",
    "zeros(sizes) | all 0\n",
    "eye(sizes) | the diagnoal is 1, others are 0\n",
    "arrange(s,e,step) | from s to e, with length of step\n",
    "linespace(s,e,steps) | from s to e, evenly divided into steps parts\n",
    "rand/randn(sizes) | rand is the uniform distribution $[0,1)$, randn is the normal distribution $N(0,1)$\n",
    "normal(mean, std) | normal distribution with mean and standard variance(std)\n",
    "randperm(m)  |  random permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Operation of tensor\n",
    "1. Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0674,  1.1073,  2.3698],\n",
      "        [ 1.7068,  2.0475,  1.6389],\n",
      "        [-1.5183,  0.9545, -1.5015],\n",
      "        [ 0.0825,  0.2446,  0.3342]])\n",
      "tensor([[-1.0674,  1.1073,  2.3698],\n",
      "        [ 1.7068,  2.0475,  1.6389],\n",
      "        [-1.5183,  0.9545, -1.5015],\n",
      "        [ 0.0825,  0.2446,  0.3342]])\n",
      "tensor([[-1.0674,  1.1073,  2.3698],\n",
      "        [ 1.7068,  2.0475,  1.6389],\n",
      "        [-1.5183,  0.9545, -1.5015],\n",
      "        [ 0.0825,  0.2446,  0.3342]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# method 1\n",
    "y = torch.rand(4,3)\n",
    "print(x+y)\n",
    "\n",
    "# method 2\n",
    "print(torch.add(x,y))\n",
    "\n",
    "# method 3 in-place\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Index\n",
    "   \n",
    "   Noted that the outcome of index share the memory with original data, and change one of them, another also would be changed. If you do not want change, try to use ```copy()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9816, 0.9673, 0.9888, 0.9800])\n",
      "tensor([1.1708, 1.9816, 1.5410])\n",
      "tensor([1.1708, 1.9816, 1.5410])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.rand(4,3)\n",
    "print(x[:,1])\n",
    "\n",
    "y = x[0,:]\n",
    "y += 1\n",
    "print(y)\n",
    "print(x[0, :]) # original tensor is changed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Change of dimension\n",
    "\n",
    "    ```torch.view()/torch.reshape()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8)  # -1 means this dimension is determined by other dimensions\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the return of ```torch.view()``` would share memory with origin like index. It only adjust the view of observing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3847,  1.0480,  0.6591,  0.4128],\n",
      "        [ 2.0038,  1.2163,  1.6236,  0.4877],\n",
      "        [ 0.2315,  1.1471, -0.3989,  0.5407],\n",
      "        [ 1.5644,  0.9461,  2.2039,  1.9636]])\n",
      "tensor([ 1.3847,  1.0480,  0.6591,  0.4128,  2.0038,  1.2163,  1.6236,  0.4877,\n",
      "         0.2315,  1.1471, -0.3989,  0.5407,  1.5644,  0.9461,  2.2039,  1.9636])\n"
     ]
    }
   ],
   "source": [
    "x +=1\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually, we hope the changed tensor would not effect by original mutually. So we need use the second method ```torch.reshape()```, but it doesn't guarantee the output is the copy. Hence, we recommend firstly use ```clone()``` create a copy and then utilize ```torch.view()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(1) \n",
    "print(type(x)) \n",
    "print(type(x.item()))  # value extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Broadcasting\n",
    "\n",
    "When two tenors of different shapes are computed by elements, a broadcasting mechanism may be triggered: the elements are copied appropriately so that the two tensors have the same shape and then computed by elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 3).view(1, 2)\n",
    "print(x)\n",
    "y = torch.arange(1, 4).view(3, 1)\n",
    "print(y)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since x and y are matrices of 1 row, 2 columns and 3 rows, 1 column, respectively, if x+y is to be calculated, then the 2 elements of the first row in x are broadcasted (copied) to the second and third rows, while the 3 elements of the first column in y are broadcasted (copied) to the second column.\n",
    "In this way, two matrices with 3 rows and 2 columns can be added by elements.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
